% Get 500 words here

  In conclusion, the system here sounds good, but doesn't work.
  The advantages here all have excellent impacts, reduced crime, and more jobs, however, the many downsides
  outweigh this.
  Take for example, the mental stability argument, it sounds like a good idea to incorporate this factor in the
  system's decision-making, as it could help prevent some of the most heinous crimes, however, when put into practice
  with current AI systems, and the governments' inability to create functioning software ~\cite{nhs-app-issue}, it
  would likely prove non-viable, especially with people thence feeling compelled to take a cash in hand, off the
  books' solution to their health issues.

  Furthermore, if people feel like their freedom's have already been seriously infringed on by the current COVID-19
  pandemic, then they would be even less likely to give up more of them in the future, if it entailed everything they
  do being monitored.
  A system like this would definitely need to be implemented slowly, and covertly if it were to take off, this is
  something that is very difficult in a western democracy, as it would be scrutinised heavily.
  However, current big tech companies could be the answer, as they already have a lot of our data, and they could
  potentially implement their own police system, which could, for example on facebook, block you from speaking to
  people if their system deems you to be dangerous to society.

  If these changes were made via the private sector, then it would be a lot more easy to implement, as most
  people live and work with the private sector at the core of their lives, take their essentials, to their social
  life.
  For example, Sainsbury's could stop selling you alcohol if Facebook's system thought that you would be a danger to
  society if you did.
  \\

  This all seems very Orwellian, but is already in place in China, with their social credit system, so it could
  become a reality over here at some point, be it likely through our big tech overlords.
  However, 2020 is not the time for it.
  AI is not currently accurate enough, and arresting someone for a 'pre-crime' based on potentially flawed
  predictions would be unfair, and would stand up as well as a shed in a hurricane when it comes to the courtroom.

  Instead, a better system, that would be viable in today's world would be one that simply suggests who to watch
  out for, without gathering all of that data which is arguably unethical, and a breach of privacy to gather.
  The system would of course need a human detective to make the final judgment, because right now, they are the
  best we have.
